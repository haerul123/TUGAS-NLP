{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMFJBg8wR08h907MPplwaKn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wl5BmiYWkZpi","executionInfo":{"status":"ok","timestamp":1673201320329,"user_tz":-420,"elapsed":5592,"user":{"displayName":"10219005 Haerul Pebriyansyah","userId":"10717979059779689582"}},"outputId":"07dde408-9f4c-4e13-e786-64b84c99143c"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["\n","import json\n","import string\n","import random\n","import nltk\n","nltk.download('omw-1.4')\n","import numpy as num\n","from nltk.stem import WordNetLemmatizer # It has the ability to lemmatize.\n","import tensorflow as tensorF # A multidimensional array of elements is represented by this symbol.\n","from tensorflow.keras import Sequential # Sequential groups a linear stack of layers into a tf.keras.Model\n","from tensorflow.keras.layers import Dense, Dropout\n","\n","nltk.download(\"punkt\")# required package for tokenization\n","nltk.download(\"wordnet\")# word database"]},{"cell_type":"code","source":["ourData = {\"ourIntents\": [\n","\n","             {\"tag\": \"waktu\",\n","              \"patterns\": [\"jam berapa toko itu buka?\"],\n","              \"responses\": [\"toko itu buka setiap hari kecuali hari libur\"]\n","             },\n","              {\"tag\": \"toko\",\n","              \"patterns\": [ \"dimana tempatnya\", \"dijalan mana\", \"lokasinya dimana\"],\n","              \"responses\": [\"di jalan cimacan\", \"dekat pesantren\", \"di tasikmalaya :)\"],\n","             },\n","              {\"tag\": \"produk\",\n","              \"patterns\": [ \"berapa harga kursi itu\", \"berapa harga kaca itu\"],\n","              \"responses\": [\"coba tanya ke kasir\", \"menurut data itu mahal\"]\n","             },\n","             {\"tag\": \"produk\",\n","              \"patterns\": [\"apakah masih ada?\", \"apakah masih ada kursi?\", \"apakah barang itu masih ada\", \"apakah sudah habis?\"],\n","              \"responses\": [\"masih ada\" \"masih ada, kamu butuh berapa\"]\n","             },\n","              {\"tag\": \"stop\",\n","              \"patterns\": [\"baik terimakasih\"],\n","              \"responses\": [\"sama - sama\" \"baik, sampai jumpa\"]\n","             }\n","\n","\n","]}"],"metadata":{"id":"BDxycQpHmakN","executionInfo":{"status":"ok","timestamp":1673202671987,"user_tz":-420,"elapsed":325,"user":{"displayName":"10219005 Haerul Pebriyansyah","userId":"10717979059779689582"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["lm = WordNetLemmatizer() #for getting words\n","# lists\n","ourClasses = []\n","newWords = []\n","documentX = []\n","documentY = []\n","# Each intent is tokenized into words and the patterns and their associated tags are added to their respective lists.\n","for intent in ourData[\"ourIntents\"]:\n","    for pattern in intent[\"patterns\"]:\n","        ournewTkns = nltk.word_tokenize(pattern)# tokenize the patterns\n","        newWords.extend(ournewTkns)# extends the tokens\n","        documentX.append(pattern)\n","        documentY.append(intent[\"tag\"])\n","\n","\n","    if intent[\"tag\"] not in ourClasses:# add unexisting tags to their respective classes\n","        ourClasses.append(intent[\"tag\"])\n","\n","newWords = [lm.lemmatize(word.lower()) for word in newWords if word not in string.punctuation] # set words to lowercase if not in punctuation\n","newWords = sorted(set(newWords))# sorting words\n","ourClasses = sorted(set(ourClasses))# sorting classes\n","     "],"metadata":{"id":"mHCsW-TKoDzc","executionInfo":{"status":"ok","timestamp":1673202674146,"user_tz":-420,"elapsed":333,"user":{"displayName":"10219005 Haerul Pebriyansyah","userId":"10717979059779689582"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["\n","trainingData = [] # training list array\n","outEmpty = [0] * len(ourClasses)\n","# bow model\n","for idx, doc in enumerate(documentX):\n","    bagOfwords = []\n","    text = lm.lemmatize(doc.lower())\n","    for word in newWords:\n","        bagOfwords.append(1) if word in text else bagOfwords.append(0)\n","\n","    outputRow = list(outEmpty)\n","    outputRow[ourClasses.index(documentY[idx])] = 1\n","    trainingData.append([bagOfwords, outputRow])\n","\n","random.shuffle(trainingData)\n","trainingData = num.array(trainingData, dtype=object)# coverting our data into an array afterv shuffling\n","\n","x = num.array(list(trainingData[:, 0]))# first trainig phase\n","y = num.array(list(trainingData[:, 1]))# second training phase"],"metadata":{"id":"pcJBOwrwoHMs","executionInfo":{"status":"ok","timestamp":1673202676319,"user_tz":-420,"elapsed":330,"user":{"displayName":"10219005 Haerul Pebriyansyah","userId":"10717979059779689582"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\n","iShape = (len(x[0]),)\n","oShape = len(y[0])\n","# parameter definition\n","ourNewModel = Sequential()\n","# In the case of a simple stack of layers, a Sequential model is appropriate\n","\n","# Dense function adds an output layer\n","ourNewModel.add(Dense(128, input_shape=iShape, activation=\"relu\"))\n","# The activation function in a neural network is in charge of converting the node's summed weighted input into activation of the node or output for the input in question\n","ourNewModel.add(Dropout(0.5))\n","# Dropout is used to enhance visual perception of input neurons\n","ourNewModel.add(Dense(64, activation=\"relu\"))\n","ourNewModel.add(Dropout(0.3))\n","ourNewModel.add(Dense(oShape, activation = \"softmax\"))\n","# below is a callable that returns the value to be used with no arguments\n","md = tensorF.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n","# Below line improves the numerical stability and pushes the computation of the probability distribution into the categorical crossentropy loss function.\n","ourNewModel.compile(loss='categorical_crossentropy',\n","              optimizer=md,\n","              metrics=[\"accuracy\"])\n","# Output the model in summary\n","print(ourNewModel.summary())\n","# Whilst training your Nural Network, you have the option of making the output verbose or simple.\n","ourNewModel.fit(x, y, epochs=200, verbose=1)\n","# By epochs, we mean the number of times you repeat a training set."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tcO82sL2oLOD","executionInfo":{"status":"ok","timestamp":1673202684033,"user_tz":-420,"elapsed":5871,"user":{"displayName":"10219005 Haerul Pebriyansyah","userId":"10717979059779689582"}},"outputId":"3400bb10-a7a5-44f6-e326-9fdf58dbcc5f"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_3 (Dense)             (None, 128)               2816      \n","                                                                 \n"," dropout_2 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dropout_3 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_5 (Dense)             (None, 4)                 260       \n","                                                                 \n","=================================================================\n","Total params: 11,332\n","Trainable params: 11,332\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/200\n","1/1 [==============================] - 1s 508ms/step - loss: 1.4058 - accuracy: 0.0000e+00\n","Epoch 2/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.2320 - accuracy: 0.4545\n","Epoch 3/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.9998 - accuracy: 0.6364\n","Epoch 4/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.9278 - accuracy: 0.6364\n","Epoch 5/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.7209 - accuracy: 0.7273\n","Epoch 6/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.5952 - accuracy: 0.7273\n","Epoch 7/200\n","1/1 [==============================] - 0s 16ms/step - loss: 0.5436 - accuracy: 0.8182\n","Epoch 8/200\n","1/1 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8182\n","Epoch 9/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.8182\n","Epoch 10/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8182\n","Epoch 11/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.3677 - accuracy: 0.8182\n","Epoch 12/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.2366 - accuracy: 0.9091\n","Epoch 13/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.1218 - accuracy: 1.0000\n","Epoch 14/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0757 - accuracy: 1.0000\n","Epoch 15/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0632 - accuracy: 1.0000\n","Epoch 16/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0721 - accuracy: 1.0000\n","Epoch 17/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0838 - accuracy: 1.0000\n","Epoch 18/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.1063 - accuracy: 1.0000\n","Epoch 19/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 1.0000\n","Epoch 20/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0204 - accuracy: 1.0000\n","Epoch 21/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 1.0000\n","Epoch 22/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 1.0000\n","Epoch 23/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0519 - accuracy: 1.0000\n","Epoch 24/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 25/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 1.0000\n","Epoch 26/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 27/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 1.0000\n","Epoch 28/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 29/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0076 - accuracy: 1.0000\n","Epoch 30/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0091 - accuracy: 1.0000\n","Epoch 31/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 1.0000\n","Epoch 32/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0063 - accuracy: 1.0000\n","Epoch 33/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0154 - accuracy: 1.0000\n","Epoch 34/200\n","1/1 [==============================] - 0s 12ms/step - loss: 3.0817e-04 - accuracy: 1.0000\n","Epoch 35/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.4116e-04 - accuracy: 1.0000\n","Epoch 36/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000\n","Epoch 37/200\n","1/1 [==============================] - 0s 22ms/step - loss: 4.6592e-04 - accuracy: 1.0000\n","Epoch 38/200\n","1/1 [==============================] - 0s 16ms/step - loss: 9.3124e-04 - accuracy: 1.0000\n","Epoch 39/200\n","1/1 [==============================] - 0s 15ms/step - loss: 5.9865e-04 - accuracy: 1.0000\n","Epoch 40/200\n","1/1 [==============================] - 0s 42ms/step - loss: 0.0146 - accuracy: 1.0000\n","Epoch 41/200\n","1/1 [==============================] - 0s 13ms/step - loss: 8.0879e-05 - accuracy: 1.0000\n","Epoch 42/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 43/200\n","1/1 [==============================] - 0s 14ms/step - loss: 2.9194e-04 - accuracy: 1.0000\n","Epoch 44/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000\n","Epoch 45/200\n","1/1 [==============================] - 0s 16ms/step - loss: 3.3446e-04 - accuracy: 1.0000\n","Epoch 46/200\n","1/1 [==============================] - 0s 19ms/step - loss: 6.8924e-04 - accuracy: 1.0000\n","Epoch 47/200\n","1/1 [==============================] - 0s 25ms/step - loss: 9.2620e-04 - accuracy: 1.0000\n","Epoch 48/200\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0535e-04 - accuracy: 1.0000\n","Epoch 49/200\n","1/1 [==============================] - 0s 9ms/step - loss: 5.9053e-04 - accuracy: 1.0000\n","Epoch 50/200\n","1/1 [==============================] - 0s 10ms/step - loss: 5.2503e-04 - accuracy: 1.0000\n","Epoch 51/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 52/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 53/200\n","1/1 [==============================] - 0s 9ms/step - loss: 8.3769e-06 - accuracy: 1.0000\n","Epoch 54/200\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 1.0000\n","Epoch 55/200\n","1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 56/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 57/200\n","1/1 [==============================] - 0s 17ms/step - loss: 4.3756e-04 - accuracy: 1.0000\n","Epoch 58/200\n","1/1 [==============================] - 0s 13ms/step - loss: 6.3284e-05 - accuracy: 1.0000\n","Epoch 59/200\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 60/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0417e-04 - accuracy: 1.0000\n","Epoch 61/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.5866e-04 - accuracy: 1.0000\n","Epoch 62/200\n","1/1 [==============================] - 0s 12ms/step - loss: 3.3404e-04 - accuracy: 1.0000\n","Epoch 63/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 1.0000\n","Epoch 64/200\n","1/1 [==============================] - 0s 23ms/step - loss: 6.9971e-04 - accuracy: 1.0000\n","Epoch 65/200\n","1/1 [==============================] - 0s 17ms/step - loss: 6.4697e-06 - accuracy: 1.0000\n","Epoch 66/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 67/200\n","1/1 [==============================] - 0s 12ms/step - loss: 2.5921e-05 - accuracy: 1.0000\n","Epoch 68/200\n","1/1 [==============================] - 0s 12ms/step - loss: 1.3221e-06 - accuracy: 1.0000\n","Epoch 69/200\n","1/1 [==============================] - 0s 18ms/step - loss: 4.9671e-05 - accuracy: 1.0000\n","Epoch 70/200\n","1/1 [==============================] - 0s 12ms/step - loss: 1.4272e-05 - accuracy: 1.0000\n","Epoch 71/200\n","1/1 [==============================] - 0s 13ms/step - loss: 1.1865e-04 - accuracy: 1.0000\n","Epoch 72/200\n","1/1 [==============================] - 0s 12ms/step - loss: 9.9697e-05 - accuracy: 1.0000\n","Epoch 73/200\n","1/1 [==============================] - 0s 37ms/step - loss: 9.2115e-06 - accuracy: 1.0000\n","Epoch 74/200\n","1/1 [==============================] - 0s 32ms/step - loss: 3.6085e-04 - accuracy: 1.0000\n","Epoch 75/200\n","1/1 [==============================] - 0s 24ms/step - loss: 1.0376e-04 - accuracy: 1.0000\n","Epoch 76/200\n","1/1 [==============================] - 0s 21ms/step - loss: 8.0627e-06 - accuracy: 1.0000\n","Epoch 77/200\n","1/1 [==============================] - 0s 106ms/step - loss: 3.2186e-06 - accuracy: 1.0000\n","Epoch 78/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 79/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.0687e-05 - accuracy: 1.0000\n","Epoch 80/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.1398e-06 - accuracy: 1.0000\n","Epoch 81/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.0916e-06 - accuracy: 1.0000\n","Epoch 82/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.3729e-05 - accuracy: 1.0000\n","Epoch 83/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.3611e-05 - accuracy: 1.0000\n","Epoch 84/200\n","1/1 [==============================] - 0s 8ms/step - loss: 6.2134e-05 - accuracy: 1.0000\n","Epoch 85/200\n","1/1 [==============================] - 0s 9ms/step - loss: 2.7768e-04 - accuracy: 1.0000\n","Epoch 86/200\n","1/1 [==============================] - 0s 8ms/step - loss: 3.9506e-05 - accuracy: 1.0000\n","Epoch 87/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.8411e-05 - accuracy: 1.0000\n","Epoch 88/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.6126e-05 - accuracy: 1.0000\n","Epoch 89/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.1144e-05 - accuracy: 1.0000\n","Epoch 90/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 91/200\n","1/1 [==============================] - 0s 8ms/step - loss: 5.4664e-05 - accuracy: 1.0000\n","Epoch 92/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.1402e-05 - accuracy: 1.0000\n","Epoch 93/200\n","1/1 [==============================] - 0s 7ms/step - loss: 2.7644e-05 - accuracy: 1.0000\n","Epoch 94/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0966 - accuracy: 0.9091\n","Epoch 95/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.5564e-04 - accuracy: 1.0000\n","Epoch 96/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 97/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 98/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.5199e-04 - accuracy: 1.0000\n","Epoch 99/200\n","1/1 [==============================] - 0s 8ms/step - loss: 3.9881e-06 - accuracy: 1.0000\n","Epoch 100/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.7250e-06 - accuracy: 1.0000\n","Epoch 101/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000\n","Epoch 102/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 103/200\n","1/1 [==============================] - 0s 8ms/step - loss: 8.9189e-06 - accuracy: 1.0000\n","Epoch 104/200\n","1/1 [==============================] - 0s 8ms/step - loss: 9.0164e-06 - accuracy: 1.0000\n","Epoch 105/200\n","1/1 [==============================] - 0s 8ms/step - loss: 8.9620e-06 - accuracy: 1.0000\n","Epoch 106/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.8820e-04 - accuracy: 1.0000\n","Epoch 107/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.7238e-04 - accuracy: 1.0000\n","Epoch 108/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.3203e-05 - accuracy: 1.0000\n","Epoch 109/200\n","1/1 [==============================] - 0s 8ms/step - loss: 5.9127e-04 - accuracy: 1.0000\n","Epoch 110/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.3890e-04 - accuracy: 1.0000\n","Epoch 111/200\n","1/1 [==============================] - 0s 8ms/step - loss: 6.1879e-06 - accuracy: 1.0000\n","Epoch 112/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 1.0000\n","Epoch 113/200\n","1/1 [==============================] - 0s 8ms/step - loss: 8.9621e-06 - accuracy: 1.0000\n","Epoch 114/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.3883e-05 - accuracy: 1.0000\n","Epoch 115/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.1391e-05 - accuracy: 1.0000\n","Epoch 116/200\n","1/1 [==============================] - 0s 15ms/step - loss: 4.4342e-05 - accuracy: 1.0000\n","Epoch 117/200\n","1/1 [==============================] - 0s 13ms/step - loss: 1.4284e-04 - accuracy: 1.0000\n","Epoch 118/200\n","1/1 [==============================] - 0s 9ms/step - loss: 8.4530e-07 - accuracy: 1.0000\n","Epoch 119/200\n","1/1 [==============================] - 0s 7ms/step - loss: 4.2771e-04 - accuracy: 1.0000\n","Epoch 120/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0067 - accuracy: 1.0000\n","Epoch 121/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0471 - accuracy: 1.0000\n","Epoch 122/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.8638e-04 - accuracy: 1.0000\n","Epoch 123/200\n","1/1 [==============================] - 0s 19ms/step - loss: 4.1283e-05 - accuracy: 1.0000\n","Epoch 124/200\n","1/1 [==============================] - 0s 11ms/step - loss: 3.7713e-06 - accuracy: 1.0000\n","Epoch 125/200\n","1/1 [==============================] - 0s 39ms/step - loss: 4.0103e-05 - accuracy: 1.0000\n","Epoch 126/200\n","1/1 [==============================] - 0s 27ms/step - loss: 6.1338e-06 - accuracy: 1.0000\n","Epoch 127/200\n","1/1 [==============================] - 0s 24ms/step - loss: 5.0816e-04 - accuracy: 1.0000\n","Epoch 128/200\n","1/1 [==============================] - 0s 70ms/step - loss: 1.7306e-05 - accuracy: 1.0000\n","Epoch 129/200\n","1/1 [==============================] - 0s 6ms/step - loss: 2.0481e-05 - accuracy: 1.0000\n","Epoch 130/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.9187e-04 - accuracy: 1.0000\n","Epoch 131/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.3381e-04 - accuracy: 1.0000\n","Epoch 132/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.4164e-05 - accuracy: 1.0000\n","Epoch 133/200\n","1/1 [==============================] - 0s 7ms/step - loss: 4.8441e-06 - accuracy: 1.0000\n","Epoch 134/200\n","1/1 [==============================] - 0s 7ms/step - loss: 4.5160e-05 - accuracy: 1.0000\n","Epoch 135/200\n","1/1 [==============================] - 0s 6ms/step - loss: 8.1840e-05 - accuracy: 1.0000\n","Epoch 136/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.0404e-06 - accuracy: 1.0000\n","Epoch 137/200\n","1/1 [==============================] - 0s 6ms/step - loss: 4.6632e-05 - accuracy: 1.0000\n","Epoch 138/200\n","1/1 [==============================] - 0s 7ms/step - loss: 9.1031e-06 - accuracy: 1.0000\n","Epoch 139/200\n","1/1 [==============================] - 0s 6ms/step - loss: 6.2198e-05 - accuracy: 1.0000\n","Epoch 140/200\n","1/1 [==============================] - 0s 6ms/step - loss: 6.0112e-05 - accuracy: 1.0000\n","Epoch 141/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.0295e-05 - accuracy: 1.0000\n","Epoch 142/200\n","1/1 [==============================] - 0s 5ms/step - loss: 3.1694e-05 - accuracy: 1.0000\n","Epoch 143/200\n","1/1 [==============================] - 0s 9ms/step - loss: 3.2302e-05 - accuracy: 1.0000\n","Epoch 144/200\n","1/1 [==============================] - 0s 6ms/step - loss: 1.8857e-06 - accuracy: 1.0000\n","Epoch 145/200\n","1/1 [==============================] - 0s 6ms/step - loss: 5.4303e-04 - accuracy: 1.0000\n","Epoch 146/200\n","1/1 [==============================] - 0s 11ms/step - loss: 2.0699e-06 - accuracy: 1.0000\n","Epoch 147/200\n","1/1 [==============================] - 0s 7ms/step - loss: 4.8984e-06 - accuracy: 1.0000\n","Epoch 148/200\n","1/1 [==============================] - 0s 6ms/step - loss: 1.7805e-05 - accuracy: 1.0000\n","Epoch 149/200\n","1/1 [==============================] - 0s 6ms/step - loss: 2.5531e-05 - accuracy: 1.0000\n","Epoch 150/200\n","1/1 [==============================] - 0s 6ms/step - loss: 7.8187e-04 - accuracy: 1.0000\n","Epoch 151/200\n","1/1 [==============================] - 0s 10ms/step - loss: 6.7191e-05 - accuracy: 1.0000\n","Epoch 152/200\n","1/1 [==============================] - 0s 6ms/step - loss: 2.4612e-04 - accuracy: 1.0000\n","Epoch 153/200\n","1/1 [==============================] - 0s 6ms/step - loss: 6.9878e-04 - accuracy: 1.0000\n","Epoch 154/200\n","1/1 [==============================] - 0s 55ms/step - loss: 1.1702e-04 - accuracy: 1.0000\n","Epoch 155/200\n","1/1 [==============================] - 0s 18ms/step - loss: 9.1032e-07 - accuracy: 1.0000\n","Epoch 156/200\n","1/1 [==============================] - 0s 7ms/step - loss: 4.6924e-06 - accuracy: 1.0000\n","Epoch 157/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.0435e-04 - accuracy: 1.0000\n","Epoch 158/200\n","1/1 [==============================] - 0s 9ms/step - loss: 4.0958e-05 - accuracy: 1.0000\n","Epoch 159/200\n","1/1 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 160/200\n","1/1 [==============================] - 0s 9ms/step - loss: 5.1287e-05 - accuracy: 1.0000\n","Epoch 161/200\n","1/1 [==============================] - 0s 6ms/step - loss: 4.3625e-05 - accuracy: 1.0000\n","Epoch 162/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.0533e-05 - accuracy: 1.0000\n","Epoch 163/200\n","1/1 [==============================] - 0s 7ms/step - loss: 5.9170e-06 - accuracy: 1.0000\n","Epoch 164/200\n","1/1 [==============================] - 0s 8ms/step - loss: 5.9604e-06 - accuracy: 1.0000\n","Epoch 165/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.4088e-06 - accuracy: 1.0000\n","Epoch 166/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.9832e-06 - accuracy: 1.0000\n","Epoch 167/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.9299e-04 - accuracy: 1.0000\n","Epoch 168/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.5356e-05 - accuracy: 1.0000\n","Epoch 169/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 170/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.9165e-04 - accuracy: 1.0000\n","Epoch 171/200\n","1/1 [==============================] - 0s 6ms/step - loss: 7.0301e-05 - accuracy: 1.0000\n","Epoch 172/200\n","1/1 [==============================] - 0s 7ms/step - loss: 3.0344e-06 - accuracy: 1.0000\n","Epoch 173/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.1332e-04 - accuracy: 1.0000\n","Epoch 174/200\n","1/1 [==============================] - 0s 8ms/step - loss: 7.8886e-04 - accuracy: 1.0000\n","Epoch 175/200\n","1/1 [==============================] - 0s 7ms/step - loss: 7.3907e-06 - accuracy: 1.0000\n","Epoch 176/200\n","1/1 [==============================] - 0s 9ms/step - loss: 8.6155e-05 - accuracy: 1.0000\n","Epoch 177/200\n","1/1 [==============================] - 0s 8ms/step - loss: 3.9772e-06 - accuracy: 1.0000\n","Epoch 178/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 179/200\n","1/1 [==============================] - 0s 6ms/step - loss: 1.1061e-04 - accuracy: 1.0000\n","Epoch 180/200\n","1/1 [==============================] - 0s 7ms/step - loss: 2.8935e-06 - accuracy: 1.0000\n","Epoch 181/200\n","1/1 [==============================] - 0s 6ms/step - loss: 3.5713e-05 - accuracy: 1.0000\n","Epoch 182/200\n","1/1 [==============================] - 0s 6ms/step - loss: 2.1370e-05 - accuracy: 1.0000\n","Epoch 183/200\n","1/1 [==============================] - 0s 8ms/step - loss: 3.2512e-08 - accuracy: 1.0000\n","Epoch 184/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.0404e-06 - accuracy: 1.0000\n","Epoch 185/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 186/200\n","1/1 [==============================] - 0s 6ms/step - loss: 2.5670e-05 - accuracy: 1.0000\n","Epoch 187/200\n","1/1 [==============================] - 0s 48ms/step - loss: 3.4658e-04 - accuracy: 1.0000\n","Epoch 188/200\n","1/1 [==============================] - 0s 39ms/step - loss: 1.0089e-05 - accuracy: 1.0000\n","Epoch 189/200\n","1/1 [==============================] - 0s 105ms/step - loss: 2.0374e-06 - accuracy: 1.0000\n","Epoch 190/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.5142e-06 - accuracy: 1.0000\n","Epoch 191/200\n","1/1 [==============================] - 0s 21ms/step - loss: 4.9958e-06 - accuracy: 1.0000\n","Epoch 192/200\n","1/1 [==============================] - 0s 13ms/step - loss: 9.3092e-05 - accuracy: 1.0000\n","Epoch 193/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.5897e-05 - accuracy: 1.0000\n","Epoch 194/200\n","1/1 [==============================] - 0s 11ms/step - loss: 2.4901e-05 - accuracy: 1.0000\n","Epoch 195/200\n","1/1 [==============================] - 0s 8ms/step - loss: 8.3227e-06 - accuracy: 1.0000\n","Epoch 196/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.9073e-06 - accuracy: 1.0000\n","Epoch 197/200\n","1/1 [==============================] - 0s 9ms/step - loss: 6.1338e-06 - accuracy: 1.0000\n","Epoch 198/200\n","1/1 [==============================] - 0s 9ms/step - loss: 3.2573e-05 - accuracy: 1.0000\n","Epoch 199/200\n","1/1 [==============================] - 0s 7ms/step - loss: 4.3349e-08 - accuracy: 1.0000\n","Epoch 200/200\n","1/1 [==============================] - 0s 8ms/step - loss: 6.7998e-04 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fdeb9ba41f0>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["\n","def ourText(text):\n","  newtkns = nltk.word_tokenize(text)\n","  newtkns = [lm.lemmatize(word) for word in newtkns]\n","  return newtkns\n","\n","def wordBag(text, vocab):\n","  newtkns = ourText(text)\n","  bagOwords = [0] * len(vocab)\n","  for w in newtkns:\n","    for idx, word in enumerate(vocab):\n","      if word == w:\n","        bagOwords[idx] = 1\n","  return num.array(bagOwords)\n","\n","def Pclass(text, vocab, labels):\n","  bagOwords = wordBag(text, vocab)\n","  ourResult = ourNewModel.predict(num.array([bagOwords]))[0]\n","  newThresh = 0.2\n","  yp = [[idx, res] for idx, res in enumerate(ourResult) if res > newThresh]\n","\n","  yp.sort(key=lambda x: x[1], reverse=True)\n","  newList = []\n","  for r in yp:\n","    newList.append(labels[r[0]])\n","  return newList\n","\n","def getRes(firstlist, fJson):\n","  tag = firstlist[0]\n","  listOfIntents = fJson[\"ourIntents\"]\n","  for i in listOfIntents:\n","    if i[\"tag\"] == tag:\n","      ourResult = random.choice(i[\"responses\"])\n","      break\n","  return ourResult"],"metadata":{"id":"ERnj6Us-oQhz","executionInfo":{"status":"ok","timestamp":1673202688032,"user_tz":-420,"elapsed":333,"user":{"displayName":"10219005 Haerul Pebriyansyah","userId":"10717979059779689582"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["while True:\n","    newMessage = input(\"\")\n","    intents = Pclass(newMessage, newWords, ourClasses)\n","    ourResult = getRes(intents, ourData)\n","    print(ourResult)"],"metadata":{"id":"KUoBXtr_qW-K"},"execution_count":null,"outputs":[]}]}